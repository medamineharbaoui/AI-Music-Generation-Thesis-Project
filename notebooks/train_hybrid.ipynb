{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb3a4aee",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import pickle\n",
    "import numpy as np\n",
    "from music21 import converter, instrument, note, chord\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense, Dropout, LSTM, Embedding, MultiHeadAttention, LayerNormalization\n",
    "from keras.utils import to_categorical\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.optimizers import Adam\n",
    "import tensorflow as tf\n",
    "import os\n",
    "\n",
    "# Create output directories\n",
    "os.makedirs(\"/kaggle/working/hybrid_outputs/model_notes\", exist_ok=True)\n",
    "os.makedirs(\"/kaggle/working/hybrid_outputs/weights\", exist_ok=True)\n",
    "\n",
    "# Check GPU availability\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "\n",
    "def train_hybrid():\n",
    "    \"\"\" Trains a hybrid LSTM-Transformer model to generate music \"\"\"\n",
    "    # Check for saved notes file\n",
    "    notes_file = \"/kaggle/input/utiles/notes.pkl\"\n",
    "    if os.path.exists(notes_file):\n",
    "        try:\n",
    "            with open(notes_file, 'rb') as filepath:\n",
    "                notes = pickle.load(filepath)\n",
    "            print(f\"Loaded {len(notes)} notes from {notes_file}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading notes file: {e}. Parsing MIDI files instead.\")\n",
    "            notes = get_notes()\n",
    "    else:\n",
    "        print(f\"No notes file found at {notes_file}. Parsing MIDI files.\")\n",
    "        notes = get_notes()\n",
    "    \n",
    "    print(f\"Total notes extracted: {len(notes)}\")\n",
    "    if len(notes) < 25:\n",
    "        raise ValueError(f\"Not enough notes ({len(notes)}) to create sequences of length 25\")\n",
    "    vocab_size = len(set(notes))  # Vocabulary size\n",
    "    print(f\"Vocabulary size: {vocab_size}\")\n",
    "    network_input, network_output = prepare_sequences(notes, vocab_size)\n",
    "    model = create_hybrid_model(network_input, vocab_size)\n",
    "    \n",
    "    # Check for last epoch and weights\n",
    "    start_epoch = 0\n",
    "    last_epoch_file = \"/kaggle/input/utiles/last_epoch.txt\"\n",
    "    weights_dir = \"/kaggle/input/utiles/*.keras\"\n",
    "    weights_files = glob.glob(weights_dir)\n",
    "    \n",
    "    if os.path.exists(last_epoch_file) and weights_files:\n",
    "        try:\n",
    "            with open(last_epoch_file, 'r') as f:\n",
    "                start_epoch = int(f.read().strip())\n",
    "            latest_weights = max(weights_files, key=os.path.getctime)  # Get most recent .keras file\n",
    "            print(f\"Resuming training from epoch {start_epoch}, loading weights from {latest_weights}\")\n",
    "            model.load_weights(latest_weights)\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading last epoch or weights: {e}. Starting training from epoch 0.\")\n",
    "            start_epoch = 0\n",
    "    else:\n",
    "        print(\"No last epoch file or weights found in /kaggle/input/utiles/. Starting training from epoch 0.\")\n",
    "    \n",
    "    train_model(model, network_input, network_output, start_epoch)\n",
    "\n",
    "def get_notes():\n",
    "    \"\"\" Gets all notes and chords with their durations from MIDI files \"\"\"\n",
    "    notes = []\n",
    "    # Use Chopin dataset\n",
    "    midi_path = \"/kaggle/input/transposed-4artists-dataset/*.mid\"\n",
    "    files = glob.glob(midi_path) #[:100]  \n",
    "    print(f\"Found {len(files)} MIDI files\")\n",
    "    if not files:\n",
    "        raise FileNotFoundError(f\"No MIDI files found at {midi_path}\")\n",
    "    for file in files:\n",
    "        try:\n",
    "            midi = converter.parse(file)\n",
    "            print(f\"Parsing {file}\")\n",
    "            notes_to_parse = None\n",
    "            try:\n",
    "                s2 = instrument.partitionByInstrument(midi)\n",
    "                notes_to_parse = s2.parts[0].recurse()\n",
    "            except:\n",
    "                notes_to_parse = midi.flat.notes\n",
    "            for element in notes_to_parse:\n",
    "                duration = element.duration.quarterLength\n",
    "                if duration < 0.75:\n",
    "                    duration_class = 'short'\n",
    "                elif duration < 1.5:\n",
    "                    duration_class = 'medium'\n",
    "                else:\n",
    "                    duration_class = 'long'\n",
    "                if isinstance(element, note.Note):\n",
    "                    note_str = f\"{str(element.pitch)}_{duration_class}\"\n",
    "                    notes.append(note_str)\n",
    "                elif isinstance(element, chord.Chord):\n",
    "                    chord_str = f\"{'.'.join(str(n) for n in element.normalOrder)}_{duration_class}\"\n",
    "                    notes.append(chord_str)\n",
    "        except Exception as e:\n",
    "            print(f\"Error parsing {file}: {e}\")\n",
    "    # Save notes to Kaggle's working directory\n",
    "    with open('/kaggle/working/hybrid_outputs/model_notes/notes.pkl', 'wb') as filepath:\n",
    "        pickle.dump(notes, filepath)\n",
    "    print(f\"Saved {len(notes)} notes to /kaggle/working/hybrid_outputs/model_notes/notes.pkl\")\n",
    "    return notes\n",
    "\n",
    "def prepare_sequences(notes, vocab_size):\n",
    "    \"\"\" Prepares the sequences used by the hybrid model \"\"\"\n",
    "    sequence_length = 25\n",
    "    note_names = sorted(set(notes))\n",
    "    note_to_int = dict((note, number) for number, note in enumerate(note_names))\n",
    "    network_input = []\n",
    "    network_output = []\n",
    "    for i in range(len(notes) - sequence_length):\n",
    "        input_sequence = notes[i:i + sequence_length]\n",
    "        output_sequence = notes[i + sequence_length]\n",
    "        network_input.append([note_to_int[char] for char in input_sequence])\n",
    "        network_output.append(note_to_int[output_sequence])\n",
    "    if not network_input:\n",
    "        raise ValueError(\"No sequences generated. Ensure notes list is long enough.\")\n",
    "    network_input = np.array(network_input)\n",
    "    network_output = to_categorical(network_output, num_classes=vocab_size)\n",
    "    print(f\"Generated {len(network_input)} sequences\")\n",
    "    return network_input, network_output\n",
    "\n",
    "def create_hybrid_model(network_input, vocab_size):\n",
    "    \"\"\" Creates the hybrid LSTM-Transformer model structure \"\"\"\n",
    "    sequence_length = network_input.shape[1]\n",
    "    d_model = 512  # Embedding dimension, matched to lstm_units\n",
    "    num_heads = 8  # Number of attention heads\n",
    "    dff = 512      # Feed-forward layer dimension\n",
    "    lstm_units = 512  # LSTM units\n",
    "\n",
    "    # Input layer\n",
    "    inputs = Input(shape=(sequence_length,))\n",
    "    \n",
    "    # Embedding layer\n",
    "    x = Embedding(input_dim=vocab_size, output_dim=d_model)(inputs)\n",
    "    \n",
    "    # LSTM layers\n",
    "    x = LSTM(lstm_units, return_sequences=True, recurrent_dropout=0.3)(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    x = LSTM(lstm_units, return_sequences=True, recurrent_dropout=0.3)(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    \n",
    "    # Transformer block\n",
    "    attn_output = MultiHeadAttention(num_heads=num_heads, key_dim=d_model // num_heads)(x, x)\n",
    "    attn_output = Dropout(0.1)(attn_output)\n",
    "    out1 = LayerNormalization(epsilon=1e-6)(x + attn_output)\n",
    "    ffn_output = Dense(dff, activation='relu')(out1)\n",
    "    ffn_output = Dense(d_model)(ffn_output)  # Output d_model to match out1\n",
    "    ffn_output = Dropout(0.1)(ffn_output)\n",
    "    x = LayerNormalization(epsilon=1e-6)(out1 + ffn_output)\n",
    "    \n",
    "    # Output layer\n",
    "    x = Dense(256, activation='relu')(x[:, -1, :])  # Take last timestep\n",
    "    x = Dropout(0.3)(x)\n",
    "    outputs = Dense(vocab_size, activation='softmax')(x)\n",
    "    \n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "    model.compile(optimizer=Adam(learning_rate=0.001), loss='categorical_crossentropy')\n",
    "    return model\n",
    "\n",
    "def train_model(model, network_input, network_output, start_epoch):\n",
    "    \"\"\" Trains the hybrid model \"\"\"\n",
    "    # Save weights every epoch in Kaggle's working directory\n",
    "    os.makedirs('/kaggle/working/hybrid_outputs/weights', exist_ok=True)\n",
    "    filepath = \"/kaggle/working/hybrid_outputs/weights/weights_hybrid-epoch{epoch:02d}-loss{loss:.4f}.keras\"\n",
    "    checkpoint = ModelCheckpoint(\n",
    "        filepath,\n",
    "        monitor='loss',\n",
    "        verbose=1,\n",
    "        save_best_only=False,\n",
    "        save_weights_only=False,\n",
    "        mode='min'\n",
    "    )\n",
    "    \n",
    "    # Custom callback to save last epoch\n",
    "    class SaveLastEpoch(tf.keras.callbacks.Callback):\n",
    "        def on_epoch_end(self, epoch, logs=None):\n",
    "            with open('/kaggle/working/hybrid_outputs/last_epoch.txt', 'w') as f:\n",
    "                f.write(str(epoch + 1))\n",
    "    \n",
    "    callbacks_list = [checkpoint, SaveLastEpoch()]\n",
    "    \n",
    "    # Train from start_epoch to 150\n",
    "    model.fit(\n",
    "        network_input, \n",
    "        network_output, \n",
    "        epochs=150, \n",
    "        batch_size=64, \n",
    "        callbacks=callbacks_list, \n",
    "        verbose=1,\n",
    "        initial_epoch=start_epoch\n",
    "    )\n",
    "\n",
    "def generate_music(model, network_input, note_names, sequence_length=25, generation_length=100):\n",
    "    \"\"\" Generates music using the trained hybrid model \"\"\"\n",
    "    start = np.random.randint(0, len(network_input) - 1)\n",
    "    pattern = network_input[start].copy()\n",
    "    int_to_note = dict((number, note) for number, note in enumerate(note_names))\n",
    "    prediction_output = []\n",
    "    \n",
    "    for _ in range(generation_length):\n",
    "        prediction_input = np.reshape(pattern, (1, sequence_length))\n",
    "        prediction = model.predict(prediction_input, verbose=0)\n",
    "        index = np.argmax(prediction)\n",
    "        result = int_to_note[index]\n",
    "        prediction_output.append(result)\n",
    "        pattern = np.append(pattern[1:], index)\n",
    "    \n",
    "    return prediction_output\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    try:\n",
    "        train_hybrid()\n",
    "    except Exception as e:\n",
    "        print(f\"Training failed: {e}\")\n",
    "    # Optional: Generate music after training (uncomment after training)\n",
    "    # notes = get_notes()\n",
    "    # vocab_size = len(set(notes))\n",
    "    # network_input, _ = prepare_sequences(notes, vocab_size)\n",
    "    # model = create_hybrid_model(network_input, vocab_size)\n",
    "    # model.load_weights(latest_weights_file)  # Load your trained weights\n",
    "    # generated = generate_music(model, network_input, sorted(set(notes)))\n",
    "    # print(\"Generated music:\", generated)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
